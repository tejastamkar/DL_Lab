{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDDQk1IHv2Uz",
        "outputId": "2dea704b-27a3-4068-fdb7-e38a9324364a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 500)\n",
            "x_test shape: (25000, 500)\n",
            "Build model...\n",
            "Train...\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 46ms/step - accuracy: 0.5812 - loss: 0.6569 - val_accuracy: 0.7569 - val_loss: 0.5010\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8254 - loss: 0.3973 - val_accuracy: 0.8133 - val_loss: 0.4518\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.8410 - loss: 0.3712 - val_accuracy: 0.8227 - val_loss: 0.4600\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.9321 - loss: 0.1822 - val_accuracy: 0.7325 - val_loss: 0.6737\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9752 - loss: 0.0798 - val_accuracy: 0.7322 - val_loss: 0.7900\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7277 - loss: 0.8046\n",
            "Test score: 0.7900190353393555\n",
            "Test accuracy: 0.7322400212287903\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "maxlen = 500  # Cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 32\n",
        "\n",
        "# Load the IMDB dataset\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "# Pad sequences to the same length\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "# Build the RNN model\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32))  # Using a SimpleRNN layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,  # Adjust the number of epochs as needed\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(x_test[:5]) # Predicting first 5 samples\n",
        "for i, prediction in enumerate(predictions):\n",
        "    sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
        "    print(f\"Prediction {i+1}: {prediction[0]:.4f} ({sentiment})\")\n",
        "    print(\"-\" * 35)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLk4RmJIw0OT",
        "outputId": "cf4e12e5-c9b0-4130-d199-ee6afe82d61c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Prediction 1: 0.0059 (Negative)\n",
            "-----------------------------------\n",
            "Prediction 2: 0.9435 (Positive)\n",
            "-----------------------------------\n",
            "Prediction 3: 0.0428 (Negative)\n",
            "-----------------------------------\n",
            "Prediction 4: 0.0046 (Negative)\n",
            "-----------------------------------\n",
            "Prediction 5: 0.9947 (Positive)\n",
            "-----------------------------------\n"
          ]
        }
      ]
    }
  ]
}